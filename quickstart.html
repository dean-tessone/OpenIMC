

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Quick Start &mdash; OpenIMC 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=01f34227"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Core pipeline API" href="api_core.html" />
    <link rel="prev" title="Installation" href="installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            OpenIMC
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Quick Start</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#gui-mode">GUI Mode</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#basic-workflow">Basic Workflow</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#more-analyses-and-features-in-openimc">More Analyses and Features in OpenIMC</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api_core.html">Core pipeline API</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_cli.html">CLI API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">OpenIMC</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Quick Start</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/quickstart.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="quick-start">
<h1>Quick Start<a class="headerlink" href="#quick-start" title="Link to this heading"></a></h1>
<p>This quick tutorial walks you through launching OpenIMC, loading an IMC file, visualizing channels, and running a basic segmentation workflow.</p>
<section id="gui-mode">
<h2>GUI Mode<a class="headerlink" href="#gui-mode" title="Link to this heading"></a></h2>
<p>Start the GUI after activating your conda environment:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>main.py
</pre></div>
</div>
<p>This opens the full OpenIMC interface.</p>
<section id="basic-workflow">
<h3>Basic Workflow<a class="headerlink" href="#basic-workflow" title="Link to this heading"></a></h3>
<ol class="arabic">
<li><p>Open an IMC file</p>
<p>Select <strong>File → Open File/Folder</strong>, then choose the <code class="docutils literal notranslate"><span class="pre">.mcd</span></code> file(s) you want to analyze.
Multiple files can be selected using Shift or Ctrl.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="_images/FileSelection_GUI.png"><img alt="File Selection in GUI" src="_images/FileSelection_GUI.png" style="width: 600px;" />
</a>
<figcaption>
<p><span class="caption-text"><strong>Figure 1:</strong> Selecting one or more <code class="docutils literal notranslate"><span class="pre">.mcd</span></code> files in the OpenIMC GUI.</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
</li>
<li><p>Explore the image</p>
<p>Newly loaded files appear in the image viewer. By default, channels are shown in a grid layout.</p>
<figure class="align-center" id="id2">
<a class="reference internal image-reference" href="_images/MultiChannelImageView.png"><img alt="View of 3 channels in grid view" src="_images/MultiChannelImageView.png" style="width: 800px;" />
</a>
<figcaption>
<p><span class="caption-text"><strong>Figure 2:</strong> Grid-based visualization of multiple IMC channels.</span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Switch to grayscale by enabling <strong>Grayscale mode</strong>.</p>
<p>To view channels as a composite RGB image, disable <strong>Grid view for multiple channels</strong>.
A dropdown will appear to assign channels to R, G, and B. Composite intensity is computed using the selected merge method.</p>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="_images/RGB_view.png"><img alt="View of 3 channels in RGB view" src="_images/RGB_view.png" style="width: 1000px;" />
</a>
<figcaption>
<p><span class="caption-text"><strong>Figure 3:</strong> RGB composite view generated from user-selected channels.</span><a class="headerlink" href="#id3" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Additional tools:
- <strong>Custom scaling</strong>: interactively rescale intensities.
- <strong>Scale bar</strong>: add and configure a micrometer scale bar.</p>
<p>These options help you quickly assess signal quality, contrast, and cell morphology.</p>
</li>
<li><p>Run segmentation</p>
<p>Click <strong>Cell Segmentation</strong> to open the segmentation dialog.
Choose a segmentation method and select the channels appropriate for your experiment.</p>
<p>Available segmentation engines:
- DeepCell CellSAM
- Cellpose cyto3 (cytoplasm + nucleus)
- Cellpose nuclei model
- Ilastik (<code class="docutils literal notranslate"><span class="pre">.ilp</span></code> models)
- Watershed</p>
<p>For most datasets, <strong>DeepCell CellSAM</strong> provides the best overall performance.
DeepCell CellSAM is a transformer based model and requires a GPU to run quickly (CPU still works, but will be slow).
If you do not have a GPU, Cellpose is a potential alternative, but will still be slow on CPU.</p>
<p>If using CellSAM, enter your DeepCell API token under <strong>DeepCell CellSAM Parameters</strong>.
Adjustable CellSAM options:
- <strong>Bbox threshold</strong> (default 0.4)
- <strong>Use WSI mode</strong> (tiling for large images)
- <strong>Low contrast enhancement</strong>
- <strong>Gauge cell size</strong></p>
<p>Before segmenting an entire experiment, it is recommended to test on a single acquisition and refine settings.</p>
<p>Once segmentation completes, enable <strong>Show Overlay</strong> to visualize masks on top of any channel.</p>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="_images/segmentation.png"><img alt="Segmentation overlaid on DNA" src="_images/segmentation.png" style="width: 1000px;" />
</a>
<figcaption>
<p><span class="caption-text"><strong>Figure 4:</strong> Segmentation mask overlaid on the DNA channel after processing with DeepCell CellSAM. Masks and the raw image are shown side by side.</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
</li>
<li><p>Extract features</p>
<p>Click <strong>Feature Extraction</strong> to open the feature extraction dialog.
The primary settings in feature extraction are:
- <strong>Acquisitions</strong>: the acquisitions to extract features from (default is all acquisitions with segmentation masks)
- <strong>Output</strong>: the output directory for the features (default is the current directory)
- <strong>Denoising</strong>: the denoising method to use (for most datasets, hot pixel removal by Median 3x3 is recommended, ensure you click ‘Apply to all channels’)
- <strong>Arcsinh scaling</strong>: whether to apply arcsinh scaling to the intensity features (for most datasets, this is recommended)</p>
<figure class="align-default" id="id5">
<img alt="_static/images/feature_extraction.png:alt:RecommendedSettingsforFeatureExtractionforMostDatasets:width:1000px:align:center" src="_static/images/feature_extraction.png:alt:RecommendedSettingsforFeatureExtractionforMostDatasets:width:1000px:align:center" />
<figcaption>
<p><span class="caption-text"><strong>Figure 5:</strong> Recommended Settings for Feature Extraction for Most Datasets.</span><a class="headerlink" href="#id5" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Click ‘Extract Features’ to start the feature extraction process.
The features will be saved to the output directory as a CSV file.
The data will continue to be stored in memory for further analysis, including clustering and spatial analysis and does not need to be reloaded.</p>
</li>
<li><p>Cluster cells</p>
<p>Click <strong>Cell Clustering</strong> to open the clustering dialog.
The features extracted from the previous step will be loaded automatically.</p>
<p>At the top of the clustering dialog, you can select the type of clustering to perform.
Available clustering methods:
- Leiden
- Louvain
- Hierarchical
- K-means
- HDBSCAN</p>
<p>Leiden and louvain are recommended for most datasets with high cell density and highly varying types of cells.
Hierarchical clustering is recommended for datasets with a small number of cells or a small number of cell types.
K-means is recommended for datasets with approximately equal numbers of cells of each type.
HDBSCAN is recommended for datasets with many outliers or cells that are not well-defined.</p>
<p>After selecting the clustering method, you can set the parameters for the clustering method. See the Clustering section for more details.
For most datasets, the default settings will be sufficient.</p>
<p>We recommend using Leiden clustering for most datasets.</p>
<figure class="align-center" id="id6">
<a class="reference internal image-reference" href="_images/clustering_settings.png"><img alt="Clustering Dialog" src="_images/clustering_settings.png" style="width: 1000px;" />
</a>
<figcaption>
<p><span class="caption-text"><strong>Figure 6:</strong> Clustering Dialog Settings, default to Leiden clustering.</span><a class="headerlink" href="#id6" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>After you hit ‘Run Clustering’, a pop up will ask you to select the features to cluster. Features will be subset to the mean intensities and the morphological features.
At this stage, it is important to select the features that are most informative for the clustering.
If you know that certain antibodies are not working well, you should exclude them from the clustering.</p>
<figure class="align-center" id="id7">
<a class="reference internal image-reference" href="_images/clustering_feature_selection.png"><img alt="Feature Selection" src="_images/clustering_feature_selection.png" style="width: 1000px;" />
</a>
<figcaption>
<p><span class="caption-text"><strong>Figure 7:</strong> Feature Selection for Clustering.</span><a class="headerlink" href="#id7" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Once the clustering is complete, you can visualize the clusters.
The default visualization is a heatmap of the clusters.</p>
<figure class="align-center" id="id8">
<a class="reference internal image-reference" href="_images/clustering_heatmap.png"><img alt="Heatmap of the clusters" src="_images/clustering_heatmap.png" style="width: 1000px;" />
</a>
<figcaption>
<p><span class="caption-text"><strong>Figure 8:</strong> Heatmap of the clusters, with annotation of both the clusters and the patients from which the cells are derived.</span><a class="headerlink" href="#id8" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>At the bottom of the clustering dialog, you can change to various other visualizations, including UMAPs, t-SNE, Stacked Bars, Differential Expression, and Boxplot/Violin Plot.
You can also save the visualization as a PNG file by clicking the ‘Save Plot’ button.
You can also save the clustering output as a CSV file by clicking the ‘Save Clustering Output’ button. This will save the features with cluster labels and/or any manual annotations.</p>
</li>
<li><p>Cell phenotyping</p>
<p>After clustering, you can annotate the clusters by their cell type.
This is done by clicking the ‘Annotate Phenotypes’ button.</p>
<p>You can either manually annotate the clusters by typing in the cell type name or use the LLM to annotate the clusters.
The LLM will ask you for an OpenAI API key. If you do not have an OpenAI API key, you can get one by signing up for an account at <a class="reference external" href="https://openai.com/">https://openai.com/</a> (see the Installation section for more details).
You can also provide context to the LLM (such as the cancer type, the tissue type, the treatment, the patient metadata, etc.)
This will help the LLM to generate more accurate cell type annotations.</p>
<p>Note: the LLM is charged by the token, so ensure your account has enough credits.
Second Note: the LLM is not perfect, so you should manually check the annotations and correct them if necessary.</p>
<p>Once the LLM has suggested the cell types, you can choose from its suggestions and update your plot.</p>
<figure class="align-center" id="id9">
<a class="reference internal image-reference" href="_images/phenotyping.png"><img alt="Phenotyping with ChatGPT suggestions" src="_images/phenotyping.png" style="width: 1000px;" />
</a>
<figcaption>
<p><span class="caption-text"><strong>Figure 9:</strong> Phenotyping with ChatGPT suggestions.</span><a class="headerlink" href="#id9" title="Link to this image"></a></p>
</figcaption>
</figure>
</li>
<li><p>Spatial analysis</p>
<p>After clustering, you can perform spatial analysis to investigate the spatial distribution of the cells.
This is done by clicking the ‘Spatial Analysis’ button.</p>
<p>Spatial analysis is split into two windows: a simple analysis and a more advanced analysis.
For most users, the simple analysis will be sufficient.</p>
<p>The first step of spatial analysis is to build a spatial graph of the cells.
There are three methods to build the spatial graph:
- k-nearest neighbors (kNN)
- Radius
- Delaunay</p>
<p>kNN is the default method and is recommended for most datasets. K is the number of neighbors to consider for the spatial graph for each cell. Set this to a reasonable number based on the density of the cells.
Radius is recommended for datasets with a small number of cells or a small number of cell types. Radius is the radius in micrometers to consider for the spatial graph for each cell. Set this to a reasonable number based on the density of the cells.
Delaunay is recommended for datasets with a large number of cells or a large number of cell types. Delaunay is based on the Delaunay triangulation of the cells. See more details in the Spatial Analysis section.</p>
<p>Some spatial visualizations are available in the simple analysis window, including:
- Spatial visualization of the cells (represent each cell as a point, color by their cluster, and show the edges between the cells)
- Distance distribution of the cells (show the distance distribution of the cells by their cluster -&gt; what is the distribution of distances between cells of the same cluster vs. cells of different clusters?)
- Pairwise enrichment analysis (test for significant spatial co-occurrence or avoidance between cluster pairs using permutation tests)
- Community detection (detect communities in the spatial graph -&gt; rather than clustering the cells, we cluster based on the spatial relationship between the cells)</p>
<figure class="align-center" id="id10">
<a class="reference internal image-reference" href="_images/spatial_visualization.png"><img alt="Spatial Visualizations in the Simple Analysis Window" src="_images/spatial_visualization.png" style="width: 1000px;" />
</a>
<figcaption>
<p><span class="caption-text"><strong>Figure 10:</strong> Spatial Visualizations in the Simple Analysis Window.</span><a class="headerlink" href="#id10" title="Link to this image"></a></p>
</figcaption>
</figure>
</li>
</ol>
</section>
</section>
<section id="more-analyses-and-features-in-openimc">
<h2>More Analyses and Features in OpenIMC<a class="headerlink" href="#more-analyses-and-features-in-openimc" title="Link to this heading"></a></h2>
<p>This quickstart covers the essential workflow to get you started with OpenIMC. However, the application includes many additional features and advanced analysis options to support a wide range of IMC experiments. These include:</p>
<ul class="simple">
<li><p><strong>Quality Control (QC)</strong>: Tools for assessing image quality, detecting artifacts, and verifying segmentation accuracy.</p></li>
<li><p><strong>Pixel Correlation Analysis</strong>: Explore channel relationships and spatial co-localization at the pixel level.</p></li>
<li><p><strong>Advanced Spatial Analyses</strong>: Beyond the basics, the software supports expanded spatial statistics, neighborhood enrichment, proximity scores, and custom graph-building options.</p></li>
<li><p><strong>Panel Design and Spillover Tools</strong>: Functions to assist with antibody panel QC and compensation for metal spillover.</p></li>
<li><p><strong>Batch Processing, Automation, and Reports</strong>: Tools for end-to-end automated analysis, with exportable reports and visualizations.</p></li>
</ul>
<p>We recommend exploring each section of the documentation after you have completed your first analysis to take full advantage of OpenIMC’s capabilities. The documentation provides detailed step-by-step usage guides, tips, and explanations for all analysis modules.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="api_core.html" class="btn btn-neutral float-right" title="Core pipeline API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Dean Tessone.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>